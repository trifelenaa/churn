# -*- coding: utf-8 -*-
"""ML

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UxXhAiuwtul1jSceDCykuQDnXZcq1MH9

# Решение конкурса на kaggle.com

Это задание посвящено полноценному решению задачи машинного обучения.
"""

import pandas as pd
import numpy as np
from matplotlib import pyplot as plt
from sklearn.linear_model import LogisticRegression, LogisticRegressionCV
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, RobustScaler, LabelEncoder, OneHotEncoder
from sklearn.pipeline import make_pipeline
from sklearn.compose import ColumnTransformer
from sklearn.metrics import roc_auc_score

import warnings
warnings.filterwarnings("ignore")

"""# Первая часть. Исследование

## Загрузка данных
В данной части задания мы выгружаем необходимые файлы: train.csv, test.csv и submission.csv. Затем разделяем признаки на категориальные и числовые. Один из числовых столбцов оказался в формате object и в нем имелись пустые строки, так что мы посчитали mean остальных остальных строк этого столбца и заполнили им пропуски (а также перевели столбец во float). Таким образом была выполнена предобработка.
"""

#выгрузка файлов
!gdown 1ERwQ5odiK1Zvi1LtjpkzCMUswYsAX8_K  # train.csv
!gdown 1fGw_-RFwvn_LEdt91Jq-7A-wzG6mmH8r  # test.csv
!gdown 199Mt4OYZNaelT83U-HGDsEYs2YcUGQ6y  # submission.csv

data = pd.read_csv('./train.csv')

# Числовые признаки
num_cols = [
    'ClientPeriod',
    'MonthlySpending',
    'TotalSpent'
]

# Категориальные признаки
cat_cols = [
    'Sex',
    'IsSeniorCitizen',
    'HasPartner',
    'HasChild',
    'HasPhoneService',
    'HasMultiplePhoneNumbers',
    'HasInternetService',
    'HasOnlineSecurityService',
    'HasOnlineBackup',
    'HasDeviceProtection',
    'HasTechSupportAccess',
    'HasOnlineTV',
    'HasMovieSubscription',
    'HasContractPhone',
    'IsBillingPaperless',
    'PaymentMethod'
]

#обозначим колонки с признаками и целевой переменной
feature_cols = num_cols + cat_cols
target_col = 'Churn'



#предобработка
#result = data[data['TotalSpent'].str.contains(' ')] #находим пустые строки
#copy_data = data.copy()
#copy_data = copy_data.drop(index=result.index) #удаляем пустые строки из копии
#copy_data['TotalSpent'] = pd.to_numeric(copy_data['TotalSpent']) #переводим копию в числовой формат
#mean_value = copy_data['TotalSpent'].mean() #считаем mean

#data['TotalSpent'] = data['TotalSpent'].replace(' ', mean_value) #заполняем в оригинальном датасете пустые строки на mean
#data['TotalSpent'] = pd.to_numeric(data['TotalSpent']) #переводим в числовой формат

data.head()

#проверка данных
data.info()

data.isna().sum()

#выведем информацию о числовых признаках
data[num_cols].info()

"""Отсюда видим, что признак `TotalSpent` не является числовым, хотя должен. Проведем некоторое исследование, чтобы выполнить грамотный препроцессинг."""

TotalSpent = pd.to_numeric(data.TotalSpent, errors='coerce')

# найдём все строки, где значение TotalSpent не является числом
data[TotalSpent.isna()]

"""У всех полученных записей с отсутсвующим `TotalSpent` `ClientPeriod` равен 0. Найдём все остальные записи с нулевым `ClientPeriod`."""

data[data.ClientPeriod == 0]

"""Как видим у всех записей с `ClientPeriod` равным нулю `TotalSpent` не определён. Посмотрим есть ли записи с нулевым `TotalSpent`."""

data[data.TotalSpent == 0]

"""Такие записи отсутствуют. Теперь найдем записи с `ClientPeriod` равным единице."""

data[data.ClientPeriod == 1]

"""У всех строк значение `MonthlySpending` совпадает со значением `TotalSpent`. Выполним проверку на то, всегда ли так происходит."""

data[(data.MonthlySpending == TotalSpent) & (data.ClientPeriod == 1)]

data[(data.MonthlySpending == TotalSpent) & (data.ClientPeriod != 1)]

"""Все 457 записей с `ClientPeriod` равным 1 имеют одинаковые `MonthlySpending` и `TotalSpent`. А для всех записей с `ClientPeriod` отличным от нуля `MonthlySpending` не равен `TotalSpent`. В связи с этим было принято решение заполнить пропуски `TotalSpent` нулями."""

TotalSpent[TotalSpent.isna()] = 0

data.TotalSpent = TotalSpent

#повторная проверка
data[num_cols].info()

"""## Анализ данных

В данной части работы мы визуально анализируем имеющуюся у нас информацию (для наглядности везде используем plt.subplot).

1. Для численных признаков (у нас их всего три) мы построили гистограммы, используя plt.hist()

2. Для категориальных признаков сначала посчитаем количество значений для каждого признака, используем data.value_counts(), а затем построим ,bar диаграммы с помощью plt.bar().

2) Посмотрите на распределение целевой переменной и скажите, являются ли классы несбалансированными.

Второй пункт очень важен, потому что существуют задачи классификации с несбалансированными классами. Например, это может значить, что в датасете намного больше примеров 0 класса. В таких случаях нужно 1) не использовать accuracy как метрику 2) использовать методы борьбы с imbalanced dataset (обычно если датасет сильно несбалансирован, т.е. класса 1 в 20 раз меньше класса 0).
"""

#гистограммы для числовых признаков
data[num_cols].hist(figsize=(20, 4), bins=50, layout=(1,3))
plt.show()

#pie диаграммы для категориальных признаков
fig, ax = plt.subplots(len(cat_cols) // 2 + len(cat_cols) % 2, 2, figsize = (10, 25))

for index, cat_col in enumerate(cat_cols):
  value_counts = data[cat_col].value_counts()
  ax_current = ax[index // 2, index % 2]
  ax_current.set_title(cat_col)
  ax_current.pie(value_counts.values, labels=value_counts.index.to_list(), autopct='%1.1f%%')

plt.show()

# посмотрим на распределение целевой переменной
target_value_counts = data[target_col].value_counts()
plt.pie(target_value_counts.values, labels=target_value_counts.index.to_list(), autopct='%1.1f%%')

plt.show()

"""Выводы по сбалансированности:"""

print('Количество классов 1: ',data.loc[data['Churn'] == 1].shape[0])
print('Количество классов 0: ',data.loc[data['Churn'] == 0].shape[0])

"""Класс 0 представлен более чем в 2 раза чеще чем класс 1 в датасете. Нельзя сказать, что классы являются сбалансированными.

## Применение линейных моделей


В данном пункте необходимо было обработать данные для применения LogisticRegression, т.е. отнормировать числовые признаки, а категориальные закодировать one-hot-encoding'ом.

Работать можно было либо через разделение train/valid или кроссвалидацию. Мною был выбран способ с кроссвалидацией, т.е. я соединила преобразование данных и LogisticRegression в один Pipeline, который далее уже был передан в GridSearchCV. Тестируем по метрике ROC-AUC.
"""

X = data[feature_cols]
y=data[target_col]

#разделяем данные на тренировочные и тестовые выборки
X_train, X_test, y_train, y_test = train_test_split(X, y,
                                                    train_size=0.8,
                                                    test_size=0.2,
                                                    random_state=37)

#с использованием Pipeline реализуем кроссвалидацию с выбранными параметрами для GridSearchCV

pipe = make_pipeline(
    ColumnTransformer([('categorical', OneHotEncoder(sparse=False), cat_cols),
                       ('numerical', StandardScaler(), num_cols)]),
    LogisticRegression()
)

parameters = {'logisticregression__C':[200, 150, 100, 10, 1, 0.1],
              'logisticregression__max_iter':[150, 200, 300]}
CV_model = GridSearchCV(pipe, parameters, cv=5, scoring='roc_auc')
CV_model.fit(X,y)

#смотрим, какой параметр C оказался наилучшим для дальнейшего использования
best_parameters = CV_model.best_params_
best_parameters

#теперь обучаем нашу модель конкретно с лучшимими параметрами
pipe = make_pipeline(
    ColumnTransformer([('categorical', OneHotEncoder(sparse=False), cat_cols),
                       ('numerical', StandardScaler(), num_cols)]),
    LogisticRegression(C = 150, max_iter = 150)
)

pipe.fit(X_train, y_train)

model = pipe

y_test_predicted = model.predict_proba(X_test)

#выводим только один столюец, так как predict_proba дает нам значения для обоих классов, а нам нужен один
y_test_predicted[:,1]

#проверяем значение метрики
test_auc = roc_auc_score(y_test, y_test_predicted[:,1])
print(test_auc)

"""Выпишем какое лучшее качество и с какими параметрами удалось получить.

1. Лучшее значение гиперпараметра C: 150, а max_iter = 150
2. Значение метрики ROC-AUC при этом: 0.8499

## Применение градиентного бустинга

Попробуем улучшить полученные в предыдущем шаге результаты, использовав градиентный бустинг.

Будем использовать catboost, поэтому не надо кодировать категориальные признаки. Catboost сделает это сам (в .fit() надо передать cat_features=cat_cols). Численные признаки нормировать для моделей, основанных на деревьях также не нужно.

1. Разделим выборку на train/valid и протестируем catboost cо стандартными параметрами.
2. Протестируем разные значения параметров количества деревьев и learning_rate'а и оставим в коде лучшую по метрике ROC-AUC комбинацию.
"""

!pip install catboost

#импортируем библиотеку и разделим данные на тренировочную и валидационную выборки
from catboost import CatBoostClassifier

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=33)

#протестируем со стандартными параметрами
clf_standard = CatBoostClassifier()

model_catboost_1 = clf_standard.fit(
    X_train, y_train,
    cat_features=cat_cols,
    eval_set=(X_val, y_val),
    verbose=False,
    plot=True
)

y_test_predicted_3 = model_catboost_1.predict_proba(X_test)
y_test_predicted_3[:,1]


test_auc = roc_auc_score(y_test, y_test_predicted_3[:,1])
print(test_auc)

#выберем нестандартные настройки
clf = CatBoostClassifier(
    iterations=500,
    random_seed=42,
    learning_rate=0.2,
    custom_loss=['AUC']
)

model_catboost_2 = clf.fit(
    X_train, y_train,
    cat_features=cat_cols,
    eval_set=(X_val, y_val),
    verbose=False,
    plot=True
)

y_test_predicted_2 = model_catboost_2.predict_proba(X_test)
y_test_predicted_2[:,1]


test_auc = roc_auc_score(y_test, y_test_predicted_2[:,1])
print(test_auc)

"""Выпишем, какое лучшее качество и с какими параметрами удалось получить.

1. Лучшее значение гиперпараметров получилось в случае со стандартными настройками: iterations = 1000, learning_rate = 0.03
2. Значение ROC-AUC: 0.879

# Предсказания

Лучшее решение получилось в случае CatBoost со стандартными настройками, его и отправили в Stepik.
"""

best_model = model_catboost_1 # лучшая предыдущая модель

X_test = pd.read_csv('./test.csv')
submission = pd.read_csv('./submission.csv')


submission['Churn'] =  best_model.predict_proba(X_test)[:,1]
submission.to_csv('./my_submission.csv')